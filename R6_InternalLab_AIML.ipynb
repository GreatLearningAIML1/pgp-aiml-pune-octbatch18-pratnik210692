{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "R6_InternalLab_AIML.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "DOL2ncA1OB7q",
        "SZqKUEFsOB71",
        "YJRBuqXhOB7_",
        "8GoNTWXAOB8C",
        "k4INoEuTzzDi",
        "gdvobTjKzzDl",
        "L31aAceVzzDn",
        "uiKT41skzzDp",
        "AhESywOKzzDt",
        "FuohN1f0zzDw",
        "lyszmGR2zzD0",
        "iZ3dijC4zzD7"
      ]
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "sb7Epo0VOB58"
      },
      "cell_type": "markdown",
      "source": [
        "### Load tensorflow"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "fHpCNRv1OB5-",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7sxIy3LO7cLK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import Normalizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "DxJDmJqqOB6K",
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": [
        "### Collect Data"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "FhllFLyKOB6N",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4x2WLh051U2q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "B4yQKMiJOB6R",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def mount_drive(filename):\n",
        "  from google.colab import drive\n",
        "  drive.mount('/gdrive/')\n",
        "  data = pd.read_csv('/gdrive/My Drive/Colab Notebooks/' + filename)\n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u7hd9VjhbsIK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bcb2f55c-4bfa-4700-b887-69a1bca8d2dc"
      },
      "cell_type": "code",
      "source": [
        "data =mount_drive(\"prices.csv\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive/; to attempt to forcibly remount, call drive.mount(\"/gdrive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "fgkX6SEqOB6W"
      },
      "cell_type": "markdown",
      "source": [
        "### Check all columns in the dataset"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "7K8pWsNQOB6X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "b610caba-6182-4db4-dba4-7e25c8d9199e"
      },
      "cell_type": "code",
      "source": [
        "data.dtypes"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "date       object\n",
              "symbol     object\n",
              "open      float64\n",
              "close     float64\n",
              "low       float64\n",
              "high      float64\n",
              "volume    float64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "_VOBtWDl4Zk5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5e40710a-70ac-4bec-c8b7-b60daafb7111"
      },
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(851264, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "7omi-6qY4cao",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "608a47fc-d60a-46e7-847f-0bbdc1d8c11d"
      },
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>open</th>\n",
              "      <th>close</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "      <th>volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>851264.000000</td>\n",
              "      <td>851264.000000</td>\n",
              "      <td>851264.000000</td>\n",
              "      <td>851264.000000</td>\n",
              "      <td>8.512640e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>70.836986</td>\n",
              "      <td>70.857109</td>\n",
              "      <td>70.118414</td>\n",
              "      <td>71.543476</td>\n",
              "      <td>5.415113e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>83.695876</td>\n",
              "      <td>83.689686</td>\n",
              "      <td>82.877294</td>\n",
              "      <td>84.465504</td>\n",
              "      <td>1.249468e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.850000</td>\n",
              "      <td>0.860000</td>\n",
              "      <td>0.830000</td>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>33.840000</td>\n",
              "      <td>33.849998</td>\n",
              "      <td>33.480000</td>\n",
              "      <td>34.189999</td>\n",
              "      <td>1.221500e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>52.770000</td>\n",
              "      <td>52.799999</td>\n",
              "      <td>52.230000</td>\n",
              "      <td>53.310001</td>\n",
              "      <td>2.476250e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>79.879997</td>\n",
              "      <td>79.889999</td>\n",
              "      <td>79.110001</td>\n",
              "      <td>80.610001</td>\n",
              "      <td>5.222500e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1584.439941</td>\n",
              "      <td>1578.130005</td>\n",
              "      <td>1549.939941</td>\n",
              "      <td>1600.930054</td>\n",
              "      <td>8.596434e+08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                open          close            low           high  \\\n",
              "count  851264.000000  851264.000000  851264.000000  851264.000000   \n",
              "mean       70.836986      70.857109      70.118414      71.543476   \n",
              "std        83.695876      83.689686      82.877294      84.465504   \n",
              "min         0.850000       0.860000       0.830000       0.880000   \n",
              "25%        33.840000      33.849998      33.480000      34.189999   \n",
              "50%        52.770000      52.799999      52.230000      53.310001   \n",
              "75%        79.879997      79.889999      79.110001      80.610001   \n",
              "max      1584.439941    1578.130005    1549.939941    1600.930054   \n",
              "\n",
              "             volume  \n",
              "count  8.512640e+05  \n",
              "mean   5.415113e+06  \n",
              "std    1.249468e+07  \n",
              "min    0.000000e+00  \n",
              "25%    1.221500e+06  \n",
              "50%    2.476250e+06  \n",
              "75%    5.222500e+06  \n",
              "max    8.596434e+08  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "7dU6X7MpOB6c"
      },
      "cell_type": "markdown",
      "source": [
        "### Drop columns `date` and  `symbol`"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "lh_6spSKOB6e",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data.drop(columns=['date','symbol'],axis=1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "3DBv3WWYOB6q"
      },
      "cell_type": "markdown",
      "source": [
        "### Consider only first 1000 rows in the dataset for building feature set and target set"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Z_hG9rGBOB6s",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = data.head(1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4DWG_F3_4ocu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d6714c76-30cf-480f-e1e2-a182c2d21a3c"
      },
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "nNGD-Hiy4rDu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "2e837968-5603-453e-9af0-15ef5d4b4be8"
      },
      "cell_type": "code",
      "source": [
        "data.sample(5)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>open</th>\n",
              "      <th>close</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "      <th>volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>124.000000</td>\n",
              "      <td>123.089996</td>\n",
              "      <td>122.860001</td>\n",
              "      <td>124.050003</td>\n",
              "      <td>488900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>558</th>\n",
              "      <td>66.059998</td>\n",
              "      <td>65.349998</td>\n",
              "      <td>65.120003</td>\n",
              "      <td>66.070000</td>\n",
              "      <td>11972400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>443</th>\n",
              "      <td>20.730000</td>\n",
              "      <td>20.540001</td>\n",
              "      <td>20.450001</td>\n",
              "      <td>20.730000</td>\n",
              "      <td>9185600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>960</th>\n",
              "      <td>5.880000</td>\n",
              "      <td>6.170000</td>\n",
              "      <td>5.880000</td>\n",
              "      <td>6.190000</td>\n",
              "      <td>16660800.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>851</th>\n",
              "      <td>35.060001</td>\n",
              "      <td>34.849998</td>\n",
              "      <td>34.209999</td>\n",
              "      <td>35.070000</td>\n",
              "      <td>2735200.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           open       close         low        high      volume\n",
              "174  124.000000  123.089996  122.860001  124.050003    488900.0\n",
              "558   66.059998   65.349998   65.120003   66.070000  11972400.0\n",
              "443   20.730000   20.540001   20.450001   20.730000   9185600.0\n",
              "960    5.880000    6.170000    5.880000    6.190000  16660800.0\n",
              "851   35.060001   34.849998   34.209999   35.070000   2735200.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "M3UaApqYOB6x"
      },
      "cell_type": "markdown",
      "source": [
        "### Divide the data into train and test sets"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "2EkKAy7fOB6y",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X1 = data.drop(columns= \"close\" , axis = 1) \n",
        "Y1 = data[\"close\"]\n",
        "transformer = Normalizer()\n",
        "X1= transformer.fit_transform(X1)\n",
        "\n",
        "train_x, test_x,train_y,test_y = train_test_split(X1, Y1, test_size=.3, random_state=7)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "slTVpaXJu3SO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "jJnRlFWmu4z6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "v6vE4eYCOB62",
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": [
        "## Building the graph in tensorflow"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "xK0zBd1VOB64",
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": [
        "1.Define input data placeholders"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "JDrYlWTuOB66",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = tf.placeholder(dtype=tf.float32, shape=[None, 4])\n",
        "Y = tf.placeholder(dtype=tf.float32, shape=[None])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "297_qja4OB7A",
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": [
        "2.Define Weights and Bias"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "L205qPeQOB7B",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "w = tf.Variable(tf.zeros(shape=[4,1],dtype=\"float32\"))\n",
        "b = tf.Variable(tf.zeros(shape=(1),dtype=\"float32\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "HgtWA-UIOB7F",
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": [
        "3.Prediction"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "JveGlx25OB7H",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "out = tf.add(tf.matmul(X, w), b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "TL1hIwf_OB7M",
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": [
        "4.Loss (Cost) Function [Mean square error]"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "8VSWPiGXOB7P",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mse = tf.reduce_mean(tf.squared_difference(out, Y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "jzG85FUlOB7U",
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": [
        "5.GradientDescent Optimizer to minimize Loss [GradientDescentOptimizer]"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "cj802w-3OB7X",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "opt=tf.train.GradientDescentOptimizer(0.01).minimize(mse)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "xSypb_u8OB7e",
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": [
        "## Execute the Graph for 100 epochs and observe the loss"
      ]
    },
    {
      "metadata": {
        "id": "u-27dkXVKgKN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "net = tf.Session()\n",
        "net.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cagN68CvD863",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1717
        },
        "outputId": "011ee52c-9896-4706-a70c-2dd8d884576a"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "for i in range(100):\n",
        "    _,loss = net.run([opt,mse], feed_dict={X: train_x, Y: train_y})\n",
        "    print('Current Loss on iteration',i,loss)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Current Loss on iteration', 0, 8370.582)\n",
            "('Current Loss on iteration', 1, 8002.651)\n",
            "('Current Loss on iteration', 2, 7663.5664)\n",
            "('Current Loss on iteration', 3, 7351.0664)\n",
            "('Current Loss on iteration', 4, 7063.0654)\n",
            "('Current Loss on iteration', 5, 6797.644)\n",
            "('Current Loss on iteration', 6, 6553.032)\n",
            "('Current Loss on iteration', 7, 6327.598)\n",
            "('Current Loss on iteration', 8, 6119.837)\n",
            "('Current Loss on iteration', 9, 5928.3643)\n",
            "('Current Loss on iteration', 10, 5751.904)\n",
            "('Current Loss on iteration', 11, 5589.2773)\n",
            "('Current Loss on iteration', 12, 5439.4014)\n",
            "('Current Loss on iteration', 13, 5301.2754)\n",
            "('Current Loss on iteration', 14, 5173.9785)\n",
            "('Current Loss on iteration', 15, 5056.6616)\n",
            "('Current Loss on iteration', 16, 4948.5425)\n",
            "('Current Loss on iteration', 17, 4848.9004)\n",
            "('Current Loss on iteration', 18, 4757.069)\n",
            "('Current Loss on iteration', 19, 4672.4375)\n",
            "('Current Loss on iteration', 20, 4594.442)\n",
            "('Current Loss on iteration', 21, 4522.5605)\n",
            "('Current Loss on iteration', 22, 4456.3154)\n",
            "('Current Loss on iteration', 23, 4395.263)\n",
            "('Current Loss on iteration', 24, 4338.997)\n",
            "('Current Loss on iteration', 25, 4287.143)\n",
            "('Current Loss on iteration', 26, 4239.3545)\n",
            "('Current Loss on iteration', 27, 4195.312)\n",
            "('Current Loss on iteration', 28, 4154.7227)\n",
            "('Current Loss on iteration', 29, 4117.3154)\n",
            "('Current Loss on iteration', 30, 4082.8408)\n",
            "('Current Loss on iteration', 31, 4051.0693)\n",
            "('Current Loss on iteration', 32, 4021.7888)\n",
            "('Current Loss on iteration', 33, 3994.8032)\n",
            "('Current Loss on iteration', 34, 3969.9338)\n",
            "('Current Loss on iteration', 35, 3947.0142)\n",
            "('Current Loss on iteration', 36, 3925.891)\n",
            "('Current Loss on iteration', 37, 3906.4243)\n",
            "('Current Loss on iteration', 38, 3888.484)\n",
            "('Current Loss on iteration', 39, 3871.95)\n",
            "('Current Loss on iteration', 40, 3856.7122)\n",
            "('Current Loss on iteration', 41, 3842.6687)\n",
            "('Current Loss on iteration', 42, 3829.7268)\n",
            "('Current Loss on iteration', 43, 3817.799)\n",
            "('Current Loss on iteration', 44, 3806.8066)\n",
            "('Current Loss on iteration', 45, 3796.6765)\n",
            "('Current Loss on iteration', 46, 3787.3398)\n",
            "('Current Loss on iteration', 47, 3778.7356)\n",
            "('Current Loss on iteration', 48, 3770.806)\n",
            "('Current Loss on iteration', 49, 3763.4978)\n",
            "('Current Loss on iteration', 50, 3756.7625)\n",
            "('Current Loss on iteration', 51, 3750.5554)\n",
            "('Current Loss on iteration', 52, 3744.835)\n",
            "('Current Loss on iteration', 53, 3739.5627)\n",
            "('Current Loss on iteration', 54, 3734.7043)\n",
            "('Current Loss on iteration', 55, 3730.226)\n",
            "('Current Loss on iteration', 56, 3726.0999)\n",
            "('Current Loss on iteration', 57, 3722.2969)\n",
            "('Current Loss on iteration', 58, 3718.7917)\n",
            "('Current Loss on iteration', 59, 3715.5615)\n",
            "('Current Loss on iteration', 60, 3712.5847)\n",
            "('Current Loss on iteration', 61, 3709.841)\n",
            "('Current Loss on iteration', 62, 3707.3125)\n",
            "('Current Loss on iteration', 63, 3704.9822)\n",
            "('Current Loss on iteration', 64, 3702.8347)\n",
            "('Current Loss on iteration', 65, 3700.8552)\n",
            "('Current Loss on iteration', 66, 3699.0312)\n",
            "('Current Loss on iteration', 67, 3697.3506)\n",
            "('Current Loss on iteration', 68, 3695.8013)\n",
            "('Current Loss on iteration', 69, 3694.3733)\n",
            "('Current Loss on iteration', 70, 3693.0576)\n",
            "('Current Loss on iteration', 71, 3691.845)\n",
            "('Current Loss on iteration', 72, 3690.7275)\n",
            "('Current Loss on iteration', 73, 3689.6978)\n",
            "('Current Loss on iteration', 74, 3688.748)\n",
            "('Current Loss on iteration', 75, 3687.8735)\n",
            "('Current Loss on iteration', 76, 3687.0671)\n",
            "('Current Loss on iteration', 77, 3686.3242)\n",
            "('Current Loss on iteration', 78, 3685.6394)\n",
            "('Current Loss on iteration', 79, 3685.0085)\n",
            "('Current Loss on iteration', 80, 3684.4268)\n",
            "('Current Loss on iteration', 81, 3683.8906)\n",
            "('Current Loss on iteration', 82, 3683.397)\n",
            "('Current Loss on iteration', 83, 3682.9414)\n",
            "('Current Loss on iteration', 84, 3682.5225)\n",
            "('Current Loss on iteration', 85, 3682.1353)\n",
            "('Current Loss on iteration', 86, 3681.779)\n",
            "('Current Loss on iteration', 87, 3681.451)\n",
            "('Current Loss on iteration', 88, 3681.1477)\n",
            "('Current Loss on iteration', 89, 3680.869)\n",
            "('Current Loss on iteration', 90, 3680.6118)\n",
            "('Current Loss on iteration', 91, 3680.375)\n",
            "('Current Loss on iteration', 92, 3680.1567)\n",
            "('Current Loss on iteration', 93, 3679.9556)\n",
            "('Current Loss on iteration', 94, 3679.7698)\n",
            "('Current Loss on iteration', 95, 3679.5994)\n",
            "('Current Loss on iteration', 96, 3679.4417)\n",
            "('Current Loss on iteration', 97, 3679.2966)\n",
            "('Current Loss on iteration', 98, 3679.1626)\n",
            "('Current Loss on iteration', 99, 3679.0396)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "9smwOW-1OB7k",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "DOL2ncA1OB7q"
      },
      "cell_type": "markdown",
      "source": [
        "### Get the shapes and values of W and b\n",
        "\n",
        "Hint: Use sess.run(W) to get W."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ZGvtyTeuOB7r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "80609b3c-28df-4eea-8697-83a1857c5be3"
      },
      "cell_type": "code",
      "source": [
        "net.run(w).shape"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "metadata": {
        "id": "zoNn9yHzj-HP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "4a4fbf8d-f936-4add-da37-36d93b678d03"
      },
      "cell_type": "code",
      "source": [
        "net.run(w)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.5353238e-03],\n",
              "       [2.5108382e-03],\n",
              "       [2.5564777e-03],\n",
              "       [3.3674850e+01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "vhDtOv5UOB7x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "efd9dbd5-b4f1-4cdb-b6a7-bedf32696bac"
      },
      "cell_type": "code",
      "source": [
        "net.run(b).shape"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "metadata": {
        "id": "XzwfhBCWkAFt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "25de5d55-0d64-4087-85af-ebae833ad192"
      },
      "cell_type": "code",
      "source": [
        "net.run(b)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([33.674854], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "CZUAjZ5oOB78",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "net.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "YJRBuqXhOB7_"
      },
      "cell_type": "markdown",
      "source": [
        "### Linear Classification using Keras"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "8GoNTWXAOB8C",
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": [
        "### Building the simple Neural Network in Keras with one neuron in the dense hidden layer.\n",
        "#### Use Mean square error as loss function and sgd as optimizer"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "zpeL5rCTOB8D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0e9dff7d-6af5-4a88-8feb-8a8ee53b23ce"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "eYmOWu3Ta517",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Initialize Sequential model\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Dense(1,  input_shape=(4,)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Wt-HYFMEOB8G",
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": [
        "### Execute the model"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "66JGJt7GOB8H",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='sgd', loss='mean_squared_error')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H6hUPiPXt_iL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X1 = data.drop(columns= \"close\" , axis = 1) \n",
        "Y1 = data[\"close\"]\n",
        "transformer = Normalizer()\n",
        "X1= transformer.fit_transform(X1)\n",
        "\n",
        "train_x, test_x,train_y,test_y = train_test_split(X1, Y1, test_size=.3, random_state=7)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QuSzR0egddHQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3434
        },
        "outputId": "a2459a0a-5a15-484f-c253-b618b46c895e"
      },
      "cell_type": "code",
      "source": [
        "model.fit(train_x,train_y, epochs=100)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "700/700 [==============================] - 0s 91us/sample - loss: nan\n",
            "Epoch 2/100\n",
            "700/700 [==============================] - 0s 82us/sample - loss: nan\n",
            "Epoch 3/100\n",
            "700/700 [==============================] - 0s 78us/sample - loss: nan\n",
            "Epoch 4/100\n",
            "700/700 [==============================] - 0s 109us/sample - loss: nan\n",
            "Epoch 5/100\n",
            "700/700 [==============================] - 0s 86us/sample - loss: nan\n",
            "Epoch 6/100\n",
            "700/700 [==============================] - 0s 90us/sample - loss: nan\n",
            "Epoch 7/100\n",
            "700/700 [==============================] - 0s 79us/sample - loss: nan\n",
            "Epoch 8/100\n",
            "700/700 [==============================] - 0s 78us/sample - loss: nan\n",
            "Epoch 9/100\n",
            "700/700 [==============================] - 0s 81us/sample - loss: nan\n",
            "Epoch 10/100\n",
            "700/700 [==============================] - 0s 78us/sample - loss: nan\n",
            "Epoch 11/100\n",
            "700/700 [==============================] - 0s 74us/sample - loss: nan\n",
            "Epoch 12/100\n",
            "700/700 [==============================] - 0s 80us/sample - loss: nan\n",
            "Epoch 13/100\n",
            "700/700 [==============================] - 0s 90us/sample - loss: nan\n",
            "Epoch 14/100\n",
            "700/700 [==============================] - 0s 91us/sample - loss: nan\n",
            "Epoch 15/100\n",
            "700/700 [==============================] - 0s 86us/sample - loss: nan\n",
            "Epoch 16/100\n",
            "700/700 [==============================] - 0s 79us/sample - loss: nan\n",
            "Epoch 17/100\n",
            "700/700 [==============================] - 0s 88us/sample - loss: nan\n",
            "Epoch 18/100\n",
            "700/700 [==============================] - 0s 90us/sample - loss: nan\n",
            "Epoch 19/100\n",
            "700/700 [==============================] - 0s 88us/sample - loss: nan\n",
            "Epoch 20/100\n",
            "700/700 [==============================] - 0s 92us/sample - loss: nan\n",
            "Epoch 21/100\n",
            "700/700 [==============================] - 0s 113us/sample - loss: nan\n",
            "Epoch 22/100\n",
            "700/700 [==============================] - 0s 89us/sample - loss: nan\n",
            "Epoch 23/100\n",
            "700/700 [==============================] - 0s 80us/sample - loss: nan\n",
            "Epoch 24/100\n",
            "700/700 [==============================] - 0s 78us/sample - loss: nan\n",
            "Epoch 25/100\n",
            "700/700 [==============================] - 0s 83us/sample - loss: nan\n",
            "Epoch 26/100\n",
            "700/700 [==============================] - 0s 80us/sample - loss: nan\n",
            "Epoch 27/100\n",
            "700/700 [==============================] - 0s 86us/sample - loss: nan\n",
            "Epoch 28/100\n",
            "700/700 [==============================] - 0s 85us/sample - loss: nan\n",
            "Epoch 29/100\n",
            "700/700 [==============================] - 0s 86us/sample - loss: nan\n",
            "Epoch 30/100\n",
            "700/700 [==============================] - 0s 86us/sample - loss: nan\n",
            "Epoch 31/100\n",
            "700/700 [==============================] - 0s 78us/sample - loss: nan\n",
            "Epoch 32/100\n",
            "700/700 [==============================] - 0s 99us/sample - loss: nan\n",
            "Epoch 33/100\n",
            "700/700 [==============================] - 0s 114us/sample - loss: nan\n",
            "Epoch 34/100\n",
            "700/700 [==============================] - 0s 104us/sample - loss: nan\n",
            "Epoch 35/100\n",
            "700/700 [==============================] - 0s 107us/sample - loss: nan\n",
            "Epoch 36/100\n",
            "700/700 [==============================] - 0s 115us/sample - loss: nan\n",
            "Epoch 37/100\n",
            "700/700 [==============================] - 0s 120us/sample - loss: nan\n",
            "Epoch 38/100\n",
            "700/700 [==============================] - 0s 106us/sample - loss: nan\n",
            "Epoch 39/100\n",
            "700/700 [==============================] - 0s 107us/sample - loss: nan\n",
            "Epoch 40/100\n",
            "700/700 [==============================] - 0s 109us/sample - loss: nan\n",
            "Epoch 41/100\n",
            "700/700 [==============================] - 0s 106us/sample - loss: nan\n",
            "Epoch 42/100\n",
            "700/700 [==============================] - 0s 102us/sample - loss: nan\n",
            "Epoch 43/100\n",
            "700/700 [==============================] - 0s 111us/sample - loss: nan\n",
            "Epoch 44/100\n",
            "700/700 [==============================] - 0s 107us/sample - loss: nan\n",
            "Epoch 45/100\n",
            "700/700 [==============================] - 0s 108us/sample - loss: nan\n",
            "Epoch 46/100\n",
            "700/700 [==============================] - 0s 103us/sample - loss: nan\n",
            "Epoch 47/100\n",
            "700/700 [==============================] - 0s 106us/sample - loss: nan\n",
            "Epoch 48/100\n",
            "700/700 [==============================] - 0s 101us/sample - loss: nan\n",
            "Epoch 49/100\n",
            "700/700 [==============================] - 0s 103us/sample - loss: nan\n",
            "Epoch 50/100\n",
            "700/700 [==============================] - 0s 141us/sample - loss: nan\n",
            "Epoch 51/100\n",
            "700/700 [==============================] - 0s 106us/sample - loss: nan\n",
            "Epoch 52/100\n",
            "700/700 [==============================] - 0s 110us/sample - loss: nan\n",
            "Epoch 53/100\n",
            "700/700 [==============================] - 0s 107us/sample - loss: nan\n",
            "Epoch 54/100\n",
            "700/700 [==============================] - 0s 103us/sample - loss: nan\n",
            "Epoch 55/100\n",
            "700/700 [==============================] - 0s 102us/sample - loss: nan\n",
            "Epoch 56/100\n",
            "700/700 [==============================] - 0s 104us/sample - loss: nan\n",
            "Epoch 57/100\n",
            "700/700 [==============================] - 0s 102us/sample - loss: nan\n",
            "Epoch 58/100\n",
            "700/700 [==============================] - 0s 107us/sample - loss: nan\n",
            "Epoch 59/100\n",
            "700/700 [==============================] - 0s 106us/sample - loss: nan\n",
            "Epoch 60/100\n",
            "700/700 [==============================] - 0s 105us/sample - loss: nan\n",
            "Epoch 61/100\n",
            "700/700 [==============================] - 0s 99us/sample - loss: nan\n",
            "Epoch 62/100\n",
            "700/700 [==============================] - 0s 101us/sample - loss: nan\n",
            "Epoch 63/100\n",
            "700/700 [==============================] - 0s 109us/sample - loss: nan\n",
            "Epoch 64/100\n",
            "700/700 [==============================] - 0s 133us/sample - loss: nan\n",
            "Epoch 65/100\n",
            "700/700 [==============================] - 0s 103us/sample - loss: nan\n",
            "Epoch 66/100\n",
            "700/700 [==============================] - 0s 103us/sample - loss: nan\n",
            "Epoch 67/100\n",
            "700/700 [==============================] - 0s 104us/sample - loss: nan\n",
            "Epoch 68/100\n",
            "700/700 [==============================] - 0s 105us/sample - loss: nan\n",
            "Epoch 69/100\n",
            "700/700 [==============================] - 0s 101us/sample - loss: nan\n",
            "Epoch 70/100\n",
            "700/700 [==============================] - 0s 106us/sample - loss: nan\n",
            "Epoch 71/100\n",
            "700/700 [==============================] - 0s 104us/sample - loss: nan\n",
            "Epoch 72/100\n",
            "700/700 [==============================] - 0s 105us/sample - loss: nan\n",
            "Epoch 73/100\n",
            "700/700 [==============================] - 0s 112us/sample - loss: nan\n",
            "Epoch 74/100\n",
            "700/700 [==============================] - 0s 103us/sample - loss: nan\n",
            "Epoch 75/100\n",
            "700/700 [==============================] - 0s 99us/sample - loss: nan\n",
            "Epoch 76/100\n",
            "700/700 [==============================] - 0s 107us/sample - loss: nan\n",
            "Epoch 77/100\n",
            "700/700 [==============================] - 0s 117us/sample - loss: nan\n",
            "Epoch 78/100\n",
            "700/700 [==============================] - 0s 121us/sample - loss: nan\n",
            "Epoch 79/100\n",
            "700/700 [==============================] - 0s 109us/sample - loss: nan\n",
            "Epoch 80/100\n",
            "700/700 [==============================] - 0s 104us/sample - loss: nan\n",
            "Epoch 81/100\n",
            "700/700 [==============================] - 0s 99us/sample - loss: nan\n",
            "Epoch 82/100\n",
            "700/700 [==============================] - 0s 105us/sample - loss: nan\n",
            "Epoch 83/100\n",
            "700/700 [==============================] - 0s 105us/sample - loss: nan\n",
            "Epoch 84/100\n",
            "700/700 [==============================] - 0s 105us/sample - loss: nan\n",
            "Epoch 85/100\n",
            "700/700 [==============================] - 0s 105us/sample - loss: nan\n",
            "Epoch 86/100\n",
            "700/700 [==============================] - 0s 105us/sample - loss: nan\n",
            "Epoch 87/100\n",
            "700/700 [==============================] - 0s 101us/sample - loss: nan\n",
            "Epoch 88/100\n",
            "700/700 [==============================] - 0s 101us/sample - loss: nan\n",
            "Epoch 89/100\n",
            "700/700 [==============================] - 0s 105us/sample - loss: nan\n",
            "Epoch 90/100\n",
            "700/700 [==============================] - 0s 111us/sample - loss: nan\n",
            "Epoch 91/100\n",
            "700/700 [==============================] - 0s 138us/sample - loss: nan\n",
            "Epoch 92/100\n",
            "700/700 [==============================] - 0s 107us/sample - loss: nan\n",
            "Epoch 93/100\n",
            "700/700 [==============================] - 0s 107us/sample - loss: nan\n",
            "Epoch 94/100\n",
            "700/700 [==============================] - 0s 110us/sample - loss: nan\n",
            "Epoch 95/100\n",
            "700/700 [==============================] - 0s 106us/sample - loss: nan\n",
            "Epoch 96/100\n",
            "700/700 [==============================] - 0s 106us/sample - loss: nan\n",
            "Epoch 97/100\n",
            "700/700 [==============================] - 0s 104us/sample - loss: nan\n",
            "Epoch 98/100\n",
            "700/700 [==============================] - 0s 99us/sample - loss: nan\n",
            "Epoch 99/100\n",
            "700/700 [==============================] - 0s 111us/sample - loss: nan\n",
            "Epoch 100/100\n",
            "700/700 [==============================] - 0s 106us/sample - loss: nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3c1f4cdc10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "metadata": {
        "id": "9YX89152dZHP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c341db2c-b1eb-4c30-e144-df9d035dc14b"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization_v1_6 (Ba multiple                  16        \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  5         \n",
            "=================================================================\n",
            "Total params: 21\n",
            "Trainable params: 13\n",
            "Non-trainable params: 8\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "k4INoEuTzzDi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Classification using Keras "
      ]
    },
    {
      "metadata": {
        "id": "mOZbqT4azzDj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gdvobTjKzzDl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Load the given Iris data using pandas (Iris.csv)"
      ]
    },
    {
      "metadata": {
        "id": "Te3tqHlVzzDm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f283d41c-160a-45fc-ae99-ba84902101d3"
      },
      "cell_type": "code",
      "source": [
        "iris= mount_drive(\"Iris-1.csv\")"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive/; to attempt to forcibly remount, call drive.mount(\"/gdrive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "S7DcFfwXesRu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "f9edb805-fcb2-463f-f88c-f233126284f9"
      },
      "cell_type": "code",
      "source": [
        "iris.dtypes"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Id                 int64\n",
              "SepalLengthCm    float64\n",
              "SepalWidthCm     float64\n",
              "PetalLengthCm    float64\n",
              "PetalWidthCm     float64\n",
              "Species           object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "metadata": {
        "id": "i3uRJiJ8ewxT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "5b50e75a-1bae-46df-ca3d-4fa9d445125e"
      },
      "cell_type": "code",
      "source": [
        "iris.head(3)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
              "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
              "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
              "2   3            4.7           3.2            1.3           0.2  Iris-setosa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "metadata": {
        "id": "JTSVZ8lknvB_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "iris[\"Species\"] = pd.Categorical(iris[\"Species\"]).codes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hAQUsqmVi-Ml",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "iris.drop(\"Id\",axis=1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L31aAceVzzDn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Splitting the data into feature set and target set"
      ]
    },
    {
      "metadata": {
        "id": "2j0DsaxCzzDo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "features = iris.drop(columns= ['Species']) \n",
        "\n",
        "target = iris[['Species']]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S-nTVZrrneCc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "c2d2ea4a-7a3b-4ae2-c52a-9310df2c7d8a"
      },
      "cell_type": "code",
      "source": [
        "features.head(2)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
              "0            5.1           3.5            1.4           0.2\n",
              "1            4.9           3.0            1.4           0.2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "metadata": {
        "id": "z-F7lHL1iPLf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "ca2282c4-8ac9-4149-d8c7-5033ef174576"
      },
      "cell_type": "code",
      "source": [
        "target.head(2)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Species\n",
              "0        0\n",
              "1        0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "metadata": {
        "id": "uiKT41skzzDp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Target set has different categories. So, Label encode them. And convert into one-hot vectors using get_dummies in pandas."
      ]
    },
    {
      "metadata": {
        "id": "m7VKFZEwzzDq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AhESywOKzzDt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Divide the dataset into Training and test (70:30)"
      ]
    },
    {
      "metadata": {
        "id": "HBAGpKTazzDt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "transformer = Normalizer()\n",
        "#features = transformer.fit_transform(features)\n",
        "\n",
        "train_x, test_x,train_y,test_y = train_test_split(features, target, test_size=.3, random_state=7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FuohN1f0zzDw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Model\n",
        "Build the model with following layers: <br>\n",
        "1. First dense layer with 10 neurons with input shape 4 (according to the feature set) <br>\n",
        "2. Second Dense layer with 8 neurons <br>\n",
        "3. Output layer with 3 neurons with softmax activation (output layer, 3 neurons as we have 3 classes) <br>\n",
        "4. Use SGD and categorical_crossentropy loss "
      ]
    },
    {
      "metadata": {
        "id": "l0kIYC3dzzDy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "model.add(tf.keras.layers.Dense(10, activation='relu', input_shape=(4,)))\n",
        "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
        "\n",
        "#Create optimizer with non-default learning rate\n",
        "sgd_optimizer = tf.keras.optimizers.SGD(lr=0.03)\n",
        "\n",
        "#Compile the model\n",
        "model.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lyszmGR2zzD0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Fitting the model and predicting "
      ]
    },
    {
      "metadata": {
        "id": "5Ezs0-JdzzD1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1071
        },
        "outputId": "490f4f6e-ab51-4bc8-beff-1b0773c76bf4"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#train model\n",
        "model.fit(features.values, target.values, validation_split=0.2, epochs=30)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 120 samples, validate on 30 samples\n",
            "Epoch 1/30\n",
            "120/120 [==============================] - 0s 2ms/sample - loss: 2.6806 - acc: 0.3917 - val_loss: 7.6843 - val_acc: 1.0000\n",
            "Epoch 2/30\n",
            "120/120 [==============================] - 0s 235us/sample - loss: 2.5675 - acc: 0.4083 - val_loss: 7.3417 - val_acc: 1.0000\n",
            "Epoch 3/30\n",
            "120/120 [==============================] - 0s 223us/sample - loss: 2.5318 - acc: 0.3500 - val_loss: 7.1432 - val_acc: 1.0000\n",
            "Epoch 4/30\n",
            "120/120 [==============================] - 0s 179us/sample - loss: 2.5153 - acc: 0.3000 - val_loss: 7.0140 - val_acc: 1.0000\n",
            "Epoch 5/30\n",
            "120/120 [==============================] - 0s 173us/sample - loss: 2.5032 - acc: 0.2333 - val_loss: 6.9226 - val_acc: 1.0000\n",
            "Epoch 6/30\n",
            "120/120 [==============================] - 0s 170us/sample - loss: 2.5021 - acc: 0.1667 - val_loss: 6.8611 - val_acc: 1.0000\n",
            "Epoch 7/30\n",
            "120/120 [==============================] - 0s 171us/sample - loss: 2.4952 - acc: 0.1583 - val_loss: 6.8173 - val_acc: 1.0000\n",
            "Epoch 8/30\n",
            "120/120 [==============================] - 0s 183us/sample - loss: 2.4932 - acc: 0.0917 - val_loss: 6.7817 - val_acc: 1.0000\n",
            "Epoch 9/30\n",
            "120/120 [==============================] - 0s 170us/sample - loss: 2.4885 - acc: 0.1000 - val_loss: 6.7551 - val_acc: 1.0000\n",
            "Epoch 10/30\n",
            "120/120 [==============================] - 0s 164us/sample - loss: 2.4866 - acc: 0.0833 - val_loss: 6.7358 - val_acc: 1.0000\n",
            "Epoch 11/30\n",
            "120/120 [==============================] - 0s 196us/sample - loss: 2.4858 - acc: 0.0833 - val_loss: 6.7186 - val_acc: 1.0000\n",
            "Epoch 12/30\n",
            "120/120 [==============================] - 0s 177us/sample - loss: 2.4846 - acc: 0.1000 - val_loss: 6.7054 - val_acc: 1.0000\n",
            "Epoch 13/30\n",
            "120/120 [==============================] - 0s 171us/sample - loss: 2.4833 - acc: 0.0917 - val_loss: 6.6935 - val_acc: 1.0000\n",
            "Epoch 14/30\n",
            "120/120 [==============================] - 0s 202us/sample - loss: 2.4840 - acc: 0.0833 - val_loss: 6.6845 - val_acc: 1.0000\n",
            "Epoch 15/30\n",
            "120/120 [==============================] - 0s 192us/sample - loss: 2.4813 - acc: 0.0917 - val_loss: 6.6771 - val_acc: 1.0000\n",
            "Epoch 16/30\n",
            "120/120 [==============================] - 0s 179us/sample - loss: 2.4824 - acc: 0.0583 - val_loss: 6.6705 - val_acc: 1.0000\n",
            "Epoch 17/30\n",
            "120/120 [==============================] - 0s 166us/sample - loss: 2.4811 - acc: 0.0833 - val_loss: 6.6640 - val_acc: 1.0000\n",
            "Epoch 18/30\n",
            "120/120 [==============================] - 0s 174us/sample - loss: 2.4812 - acc: 0.1000 - val_loss: 6.6588 - val_acc: 1.0000\n",
            "Epoch 19/30\n",
            "120/120 [==============================] - 0s 169us/sample - loss: 2.4787 - acc: 0.0667 - val_loss: 6.6545 - val_acc: 1.0000\n",
            "Epoch 20/30\n",
            "120/120 [==============================] - 0s 179us/sample - loss: 2.4801 - acc: 0.1000 - val_loss: 6.6501 - val_acc: 1.0000\n",
            "Epoch 21/30\n",
            "120/120 [==============================] - 0s 171us/sample - loss: 2.4790 - acc: 0.1250 - val_loss: 6.6461 - val_acc: 1.0000\n",
            "Epoch 22/30\n",
            "120/120 [==============================] - 0s 178us/sample - loss: 2.4782 - acc: 0.1083 - val_loss: 6.6430 - val_acc: 1.0000\n",
            "Epoch 23/30\n",
            "120/120 [==============================] - 0s 170us/sample - loss: 2.4782 - acc: 0.0917 - val_loss: 6.6398 - val_acc: 1.0000\n",
            "Epoch 24/30\n",
            "120/120 [==============================] - 0s 169us/sample - loss: 2.4787 - acc: 0.0833 - val_loss: 6.6372 - val_acc: 1.0000\n",
            "Epoch 25/30\n",
            "120/120 [==============================] - 0s 205us/sample - loss: 2.4777 - acc: 0.0833 - val_loss: 6.6350 - val_acc: 1.0000\n",
            "Epoch 26/30\n",
            "120/120 [==============================] - 0s 175us/sample - loss: 2.4767 - acc: 0.0917 - val_loss: 6.6330 - val_acc: 1.0000\n",
            "Epoch 27/30\n",
            "120/120 [==============================] - 0s 171us/sample - loss: 2.4772 - acc: 0.0917 - val_loss: 6.6317 - val_acc: 1.0000\n",
            "Epoch 28/30\n",
            "120/120 [==============================] - 0s 180us/sample - loss: 2.4775 - acc: 0.1250 - val_loss: 6.6299 - val_acc: 1.0000\n",
            "Epoch 29/30\n",
            "120/120 [==============================] - 0s 182us/sample - loss: 2.4773 - acc: 0.1167 - val_loss: 6.6286 - val_acc: 1.0000\n",
            "Epoch 30/30\n",
            "120/120 [==============================] - 0s 175us/sample - loss: 2.4766 - acc: 0.1500 - val_loss: 6.6273 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3c1f19b450>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "metadata": {
        "id": "8eJjStH_zzD3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iZ3dijC4zzD7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Report Accuracy of the predicted values"
      ]
    },
    {
      "metadata": {
        "id": "P5j8Wi1azzD8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "outputId": "56def6bd-d92e-467b-b471-fe395aec1368"
      },
      "cell_type": "code",
      "source": [
        "model.predict(test_x)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.3343727 , 0.43701422, 0.22861305],\n",
              "       [0.33349967, 0.433953  , 0.23254739],\n",
              "       [0.32862708, 0.44214615, 0.22922678],\n",
              "       [0.33403537, 0.4346533 , 0.23131132],\n",
              "       [0.33396378, 0.43791428, 0.22812201],\n",
              "       [0.33015946, 0.46877983, 0.20106064],\n",
              "       [0.33620426, 0.44070452, 0.22309113],\n",
              "       [0.33562982, 0.43675336, 0.22761692],\n",
              "       [0.32896104, 0.43865204, 0.23238684],\n",
              "       [0.33520356, 0.43550295, 0.22929351],\n",
              "       [0.3362234 , 0.43909207, 0.22468455],\n",
              "       [0.3333023 , 0.43262458, 0.23407312],\n",
              "       [0.3275916 , 0.43213642, 0.240272  ],\n",
              "       [0.3341896 , 0.4380413 , 0.22776908],\n",
              "       [0.32892352, 0.45042276, 0.22065373],\n",
              "       [0.33361825, 0.43485394, 0.23152778],\n",
              "       [0.33741942, 0.44451487, 0.2180657 ],\n",
              "       [0.33506873, 0.43801516, 0.22691616],\n",
              "       [0.32838598, 0.43483368, 0.23678036],\n",
              "       [0.32923546, 0.4531838 , 0.21758074],\n",
              "       [0.33566594, 0.4410934 , 0.22324064],\n",
              "       [0.33504993, 0.43982545, 0.22512458],\n",
              "       [0.33579886, 0.43721604, 0.22698513],\n",
              "       [0.33779895, 0.4445079 , 0.21769312],\n",
              "       [0.33709028, 0.44086656, 0.22204322],\n",
              "       [0.3346318 , 0.43699333, 0.2283749 ],\n",
              "       [0.3358096 , 0.43958798, 0.22460243],\n",
              "       [0.33606642, 0.44486192, 0.21907169],\n",
              "       [0.3350191 , 0.43993923, 0.2250417 ],\n",
              "       [0.3348435 , 0.44033048, 0.22482605],\n",
              "       [0.3357516 , 0.4395917 , 0.22465666],\n",
              "       [0.3350438 , 0.44800612, 0.21695006],\n",
              "       [0.32733798, 0.434505  , 0.23815705],\n",
              "       [0.33565816, 0.44000223, 0.22433965],\n",
              "       [0.33577317, 0.44317675, 0.2210501 ],\n",
              "       [0.32957572, 0.4511398 , 0.21928453],\n",
              "       [0.32872382, 0.45521668, 0.21605955],\n",
              "       [0.32888   , 0.43472034, 0.23639965],\n",
              "       [0.32886487, 0.44341755, 0.2277175 ],\n",
              "       [0.33622167, 0.44175157, 0.22202675],\n",
              "       [0.33462733, 0.4379736 , 0.22739905],\n",
              "       [0.33646584, 0.44676661, 0.21676756],\n",
              "       [0.33543184, 0.44180295, 0.22276522],\n",
              "       [0.33558327, 0.4392104 , 0.22520633],\n",
              "       [0.334705  , 0.43396232, 0.23133267]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "metadata": {
        "id": "XKdxjPEZyvNW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}