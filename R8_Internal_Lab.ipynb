{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "R8_Internal_Lab.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NFfDTfhlaEI_"
      },
      "source": [
        "# Transfer Learning MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rNwbqCFRaEJC"
      },
      "source": [
        "* Train a simple convnet on the MNIST dataset the first 5 digits [0..4].\n",
        "* Freeze convolutional layers and fine-tune dense layers for the classification of digits [5..9]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YUB1uDW_8XIy"
      },
      "source": [
        "## 1. Import necessary libraries for the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Rsj4t5HTaEJE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4d366723-ef77-469c-d637-ef837a241909"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense,Dropout,Activation,Flatten\n",
        "from keras.layers.convolutional import Conv2D,MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IXrn3heBaEJa"
      },
      "source": [
        "## 2. Import MNIST data and create 2 datasets with one dataset having digits from 0 to 4 and other from 5 to 9 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euoecKBcQaKi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train_0to4 = x_train[y_train < 5]\n",
        "y_train_0to4 = y_train[y_train < 5]\n",
        "x_test_0to4 = x_test[y_test < 5]\n",
        "y_test_0to4 = y_test[y_test < 5]\n",
        "\n",
        "x_train_5to9 = x_train[y_train >= 5]\n",
        "y_train_5to9 = y_train[y_train >= 5] -5\n",
        "x_test_5to9 = x_test[y_test >= 5]\n",
        "y_test_5to9 = y_test[y_test >= 5] -5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9qU14lYL9A5g"
      },
      "source": [
        "## 3. Print x_train, y_train, x_test and y_test for both the datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z9OrszhJ0SgJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5628
        },
        "outputId": "a365a564-12cf-4603-d4f8-9d50a84e0617"
      },
      "source": [
        "print (x_train_0to4[5], y_train_0to4[5], x_test_0to4[5], y_test_0to4[5])\n",
        "print (x_train_5to9[5], y_train_5to9[5], x_test_5to9[5], y_test_5to9[5])\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  38,  43,\n",
            "        105, 255, 253, 253, 253, 253, 253, 174,   6,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  43, 139, 224, 226,\n",
            "        252, 253, 252, 252, 252, 252, 252, 252, 158,  14,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 178, 252, 252, 252,\n",
            "        252, 253, 252, 252, 252, 252, 252, 252, 252,  59,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 109, 252, 252, 230,\n",
            "        132, 133, 132, 132, 189, 252, 252, 252, 252,  59,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,  29,  29,  24,\n",
            "          0,   0,   0,   0,  14, 226, 252, 252, 172,   7,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,  85, 243, 252, 252, 144,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,  88, 189, 252, 252, 252,  14,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,  91, 212, 247, 252, 252, 252, 204,   9,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  32, 125, 193, 193,\n",
            "        193, 253, 252, 252, 252, 238, 102,  28,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,  45, 222, 252, 252, 252,\n",
            "        252, 253, 252, 252, 252, 177,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,  45, 223, 253, 253, 253,\n",
            "        253, 255, 253, 253, 253, 253,  74,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  31, 123,  52,  44,\n",
            "         44,  44,  44, 143, 252, 252,  74,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,  15, 252, 252,  74,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,  86, 252, 252,  74,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   5,  75,   9,   0,   0,   0,   0,\n",
            "          0,   0,  98, 242, 252, 252,  74,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,  61, 183, 252,  29,   0,   0,   0,   0,\n",
            "         18,  92, 239, 252, 252, 243,  65,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0, 208, 252, 252, 147, 134, 134, 134, 134,\n",
            "        203, 253, 252, 252, 188,  83,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0, 208, 252, 252, 252, 252, 252, 252, 252,\n",
            "        252, 253, 230, 153,   8,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,  49, 157, 252, 252, 252, 252, 252, 217,\n",
            "        207, 146,  45,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   7, 103, 235, 252, 172, 103,  24,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0]], dtype=uint8), 3, array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  22, 192, 134,  32,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,  15,  77,   5,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,  17, 235, 250, 169,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,  15, 220, 241,  37,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,  20, 189, 253, 147,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0, 139, 253, 100,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,  70, 253, 253,  21,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,  43, 254, 173,  13,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,  22, 153, 253,  96,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,  43, 231, 254,  92,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0, 163, 255, 204,  11,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0, 104, 254, 158,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0, 162, 253, 178,   5,   0,   0,   0,\n",
            "          0,   0,   0,   9, 131, 237, 253,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0, 162, 253, 253, 191, 175,  70,  70,\n",
            "         70,  70, 133, 197, 253, 253, 169,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,  51, 228, 253, 253, 254, 253, 253,\n",
            "        253, 253, 254, 253, 253, 219,  35,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,  17,  65, 137, 254, 232, 137,\n",
            "        137, 137,  44, 253, 253, 161,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,  34, 254, 206,  21,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0, 160, 253,  69,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,  85, 254, 241,  50,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0, 158, 254, 165,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0, 231, 244,  50,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "        104, 254, 232,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "        208, 253, 157,   0,  13,  30,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "        208, 253, 154,  91, 204, 161,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "        208, 253, 254, 253, 154,  29,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         61, 190, 128,  23,   6,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0]], dtype=uint8), 4)\n",
            "(array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,  11, 203, 229,  32,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,  26,  47,  47,  30,  95, 254, 215,  13,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  45, 154,\n",
            "        185, 185, 223, 253, 253, 133, 175, 255, 188,  19,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 110, 253,\n",
            "        253, 253, 246, 161, 228, 253, 253, 254,  92,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 128, 245, 253,\n",
            "        158, 137,  21,   0,  48, 233, 253, 233,   8,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 254, 223,\n",
            "         25,   0,   0,  36, 170, 254, 244, 106,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  55, 212, 253,\n",
            "        161,  11,  26, 178, 253, 236, 113,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   7, 155, 253,\n",
            "        228,  80, 223, 253, 253, 109,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 141, 253,\n",
            "        253, 253, 254, 253, 154,  29,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 110, 253,\n",
            "        253, 253, 254, 179,  38,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3, 171, 254,\n",
            "        254, 254, 179,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 171, 253, 253,\n",
            "        253, 253, 178,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,  26, 123, 254, 253, 203,\n",
            "        156, 253, 200,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,  93, 253, 254, 121,  13,\n",
            "         93, 253, 158,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,  64, 239, 253,  76,   8,  32,\n",
            "        219, 253, 126,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0, 133, 254, 191,   0,   5, 108,\n",
            "        234, 254, 106,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0, 132, 253, 190,   5,  85, 253,\n",
            "        236, 154,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0, 153, 253, 169, 192, 253, 253,\n",
            "         77,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0, 112, 253, 253, 254, 236, 129,\n",
            "          9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,  17, 118, 243, 191, 113,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0]], dtype=uint8), 3, array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  49,\n",
            "        180, 253, 255, 253, 169,  36,  11,  76,   9,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   5,  68, 228,\n",
            "        252, 252, 253, 252, 252, 160, 189, 253,  92,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  55, 252, 252,\n",
            "        227,  79,  69,  69, 100,  90, 236, 247,  67,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  43, 233, 252, 185,\n",
            "         50,   0,   0,   0,  26, 203, 252, 135,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 168, 253, 178,  37,\n",
            "          0,   0,   0,   0,  70, 252, 252,  63,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0, 155, 253, 242,  42,   0,\n",
            "          0,   0,   0,   5, 191, 253, 190,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0, 207, 252, 230,   0,   0,\n",
            "          0,   0,   5, 136, 252, 252,  64,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0, 207, 252, 230,   0,   0,\n",
            "          0,  32, 138, 252, 252, 227,  16,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0, 165, 252, 249, 207, 207,\n",
            "        207, 228, 253, 252, 252, 160,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   9, 179, 253, 252, 252,\n",
            "        252, 252,  75, 169, 252,  56,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  64, 116, 116,\n",
            "         74,   0, 149, 253, 215,  21,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0, 253, 252, 162,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,  32, 253, 240,  50,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0, 157, 253, 164,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         43, 240, 253,  92,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         93, 253, 252,  84,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "        114, 252, 209,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "        207, 252, 116,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "        165, 252, 116,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         93, 200,  63,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0],\n",
            "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0]], dtype=uint8), 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sJswV4xk9jQS",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cB9BPFzr9oDF"
      },
      "source": [
        "## ** 4. Let us take only the dataset (x_train, y_train, x_test, y_test) for Integers 0 to 4 in MNIST **\n",
        "## Reshape x_train and x_test to a 4 Dimensional array (channel = 1) to pass it into a Conv2D layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FlQRPfFzaEJx",
        "colab": {}
      },
      "source": [
        "x_train = x_train_0to4\n",
        "y_train = y_train_0to4\n",
        "x_test = x_test_0to4\n",
        "y_test = y_test_0to4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWzbzoDASrxJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "6588307e-f792-4975-eba9-db1e5b16623a"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30596, 28, 28)\n",
            "(30596,)\n",
            "(5139, 28, 28)\n",
            "(5139,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lZk_GohSrzw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jLQr-b3F-hw8"
      },
      "source": [
        "## 5. Normalize x_train and x_test by dividing it by 255"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PlEZIAG5-g2I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "15c3e683-a853-4e52-c864-996c9facc2a0"
      },
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "#Normalizing the input\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('x_train shape:', (30596, 28, 28, 1))\n",
            "(30596, 'train samples')\n",
            "(5139, 'test samples')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pytVBaw4-vMi"
      },
      "source": [
        "## 6. Use One-hot encoding to divide y_train and y_test into required no of output classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V48xiua4-uUi",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "batch_size = 128\n",
        "num_classes = 5\n",
        "epochs = 12\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYkuVgo3Uesa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c79419f0-5c08-467b-87a3-2a518013c656"
      },
      "source": [
        "print(y_train[0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "elPkI44g_C2b"
      },
      "source": [
        "## 7. Build a sequential model with 2 Convolutional layers with 32 kernels of size (3,3) followed by a Max pooling layer of size (2,2) followed by a drop out layer to be trained for classification of digits 0-4  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MU09mm9F89gO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "b2b2b3bf-f1dc-495b-f262-fa38de0a6ea1"
      },
      "source": [
        "input_shape = (28, 28, 1)\n",
        "\n",
        "#Initialize the model\n",
        "model = Sequential()\n",
        "\n",
        "#Add a Convolutional Layer with 32 filters of size 3X3 and activation function as 'ReLU' \n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape,name='conv_1'))\n",
        "\n",
        "#Add a MaxPooling Layer of size 2X2 \n",
        "model.add(MaxPooling2D(pool_size=(2, 2),name='max_1'))\n",
        "\n",
        "#Apply Dropout with 0.25 probability \n",
        "model.add(Dropout(0.25,name='drop_1'))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sJQaycRO_3Au"
      },
      "source": [
        "## 8. Post that flatten the data and add 2 Dense layers with 128 neurons and neurons = output classes with activation = 'relu' and 'softmax' respectively. Add dropout layer inbetween if necessary  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vOZeRbK7t9AT",
        "colab": {}
      },
      "source": [
        "#Flatten the layer\n",
        "model.add(Flatten())\n",
        "\n",
        "#Add Fully Connected Layer with 128 units and activation function as 'ReLU'\n",
        "model.add(Dense(128, activation='relu',name='dense_1'))\n",
        "\n",
        "#Apply Dropout with 0.5 probability \n",
        "model.add(Dropout(0.5,name='drop_2'))\n",
        "\n",
        "#Add Fully Connected Layer with 10 units and activation function as 'softmax'\n",
        "model.add(Dense(num_classes, activation='softmax',name='dense_2'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "my1P09bxAv8H"
      },
      "source": [
        "## 9. Print the training and test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etD6y5pZWv1k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "outputId": "f2ae22a5-9040-43c8-9dc0-e255cdd9e305"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.fit(x_train,y_train,batch_size=200,nb_epoch=12,verbose=1,validation_data=(x_test,y_test))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 30596 samples, validate on 5139 samples\n",
            "Epoch 1/12\n",
            "30596/30596 [==============================] - 4s 131us/step - loss: 0.1912 - acc: 0.9419 - val_loss: 0.0476 - val_acc: 0.9860\n",
            "Epoch 2/12\n",
            "30596/30596 [==============================] - 1s 35us/step - loss: 0.0693 - acc: 0.9795 - val_loss: 0.0297 - val_acc: 0.9891\n",
            "Epoch 3/12\n",
            "30596/30596 [==============================] - 1s 36us/step - loss: 0.0454 - acc: 0.9870 - val_loss: 0.0179 - val_acc: 0.9930\n",
            "Epoch 4/12\n",
            "30596/30596 [==============================] - 1s 36us/step - loss: 0.0334 - acc: 0.9898 - val_loss: 0.0133 - val_acc: 0.9963\n",
            "Epoch 5/12\n",
            "30596/30596 [==============================] - 1s 35us/step - loss: 0.0268 - acc: 0.9920 - val_loss: 0.0145 - val_acc: 0.9938\n",
            "Epoch 6/12\n",
            "30596/30596 [==============================] - 1s 35us/step - loss: 0.0211 - acc: 0.9936 - val_loss: 0.0108 - val_acc: 0.9969\n",
            "Epoch 7/12\n",
            "30596/30596 [==============================] - 1s 35us/step - loss: 0.0179 - acc: 0.9942 - val_loss: 0.0089 - val_acc: 0.9969\n",
            "Epoch 8/12\n",
            "30596/30596 [==============================] - 1s 35us/step - loss: 0.0162 - acc: 0.9953 - val_loss: 0.0078 - val_acc: 0.9973\n",
            "Epoch 9/12\n",
            "30596/30596 [==============================] - 1s 35us/step - loss: 0.0147 - acc: 0.9954 - val_loss: 0.0079 - val_acc: 0.9977\n",
            "Epoch 10/12\n",
            "30596/30596 [==============================] - 1s 35us/step - loss: 0.0136 - acc: 0.9957 - val_loss: 0.0067 - val_acc: 0.9973\n",
            "Epoch 11/12\n",
            "30596/30596 [==============================] - 1s 35us/step - loss: 0.0127 - acc: 0.9961 - val_loss: 0.0069 - val_acc: 0.9977\n",
            "Epoch 12/12\n",
            "30596/30596 [==============================] - 1s 36us/step - loss: 0.0099 - acc: 0.9967 - val_loss: 0.0066 - val_acc: 0.9981\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f23acd2d290>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yf7F8Gdutbf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "da12bb32-0358-4d3c-9709-1c39874ef718"
      },
      "source": [
        "#Testing the model on test and train set\n",
        "score = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', score[1])\n",
        "score = model.evaluate(x_train, y_train)\n",
        "print('Train accuracy:', score[1])\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5139/5139 [==============================] - 0s 51us/step\n",
            "('Test accuracy:', 0.9980540961276513)\n",
            "30596/30596 [==============================] - 2s 49us/step\n",
            "('Train accuracy:', 0.9992155837364362)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "z78o3WIjaEJ3"
      },
      "source": [
        "## 10. Make only the dense layers to be trainable and convolutional layers to be non-trainable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "brN7VZHFaEJ4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "2c535e27-538e-406d-9a80-5d4a4b6eb868"
      },
      "source": [
        "#Freezing layers in the model which don't have 'dense' in their name\n",
        "for layer in model.layers:\n",
        "  if('dense' not in layer.name): #prefix detection to freeze layers which does not have dense\n",
        "    #Freezing a layer\n",
        "    layer.trainable = False\n",
        "\n",
        "#Module to print colourful statements\n",
        "from termcolor import colored\n",
        "\n",
        "#Check which layers have been frozen \n",
        "for layer in model.layers:\n",
        "  print (colored(layer.name, 'blue'))\n",
        "  print (colored(layer.trainable, 'red'))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34mconv_1\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mmax_1\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mdrop_1\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mflatten_1\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mdense_1\u001b[0m\n",
            "\u001b[31mTrue\u001b[0m\n",
            "\u001b[34mdrop_2\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mdense_2\u001b[0m\n",
            "\u001b[31mTrue\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4opnW7o0BJ8P"
      },
      "source": [
        "## 11. Use the model trained on 0 to 4 digit classification and train it on the dataset which has digits 5 to 9  (Using Transfer learning keeping only the dense layers to be trainable)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lCFcYHTm6-cE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "outputId": "114748bf-9d97-4c69-d4fd-ee7883d4f699"
      },
      "source": [
        "x_train_5to9 = x_train_5to9.reshape(x_train_5to9.shape[0], 28, 28, 1)\n",
        "x_test_5to9 = x_test_5to9.reshape(x_test_5to9.shape[0], 28, 28, 1)\n",
        "x_train_5to9 = x_train_5to9.astype('float32')\n",
        "x_test_5to9 = x_test_5to9.astype('float32')\n",
        "\n",
        "#Normalizing the input\n",
        "x_train_5to9 /= 255\n",
        "x_test_5to9 /= 255\n",
        "print('x_train shape:', x_train_5to9.shape)\n",
        "print(x_train_5to9.shape[0], 'train samples')\n",
        "print(x_test_5to9.shape[0], 'test samples')\n",
        "\n",
        "import keras\n",
        "batch_size = 128\n",
        "num_classes = 5\n",
        "epochs = 12\n",
        "# convert class vectors to binary class matrices\n",
        "y_train_5to9 = keras.utils.to_categorical(y_train_5to9, num_classes)\n",
        "y_test_5to9 = keras.utils.to_categorical(y_test_5to9, num_classes)\n",
        "\n",
        "\n",
        "model.fit(x_train_5to9,y_train_5to9,batch_size=200,nb_epoch=12,verbose=1,validation_data=(x_test_5to9,y_test_5to9))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('x_train shape:', (29404, 28, 28, 1))\n",
            "(29404, 'train samples')\n",
            "(4861, 'test samples')\n",
            "Train on 29404 samples, validate on 4861 samples\n",
            "Epoch 1/12\n",
            " 4200/29404 [===>..........................] - ETA: 0s - loss: 1.2158 - acc: 0.6771"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:22: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "/usr/local/lib/python2.7/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "29404/29404 [==============================] - 1s 38us/step - loss: 0.3478 - acc: 0.8996 - val_loss: 0.0726 - val_acc: 0.9759\n",
            "Epoch 2/12\n",
            "29404/29404 [==============================] - 1s 35us/step - loss: 0.1153 - acc: 0.9654 - val_loss: 0.0568 - val_acc: 0.9809\n",
            "Epoch 3/12\n",
            "29404/29404 [==============================] - 1s 35us/step - loss: 0.0826 - acc: 0.9755 - val_loss: 0.0426 - val_acc: 0.9852\n",
            "Epoch 4/12\n",
            "29404/29404 [==============================] - 1s 34us/step - loss: 0.0716 - acc: 0.9782 - val_loss: 0.0362 - val_acc: 0.9875\n",
            "Epoch 5/12\n",
            "29404/29404 [==============================] - 1s 34us/step - loss: 0.0624 - acc: 0.9810 - val_loss: 0.0349 - val_acc: 0.9875\n",
            "Epoch 6/12\n",
            "29404/29404 [==============================] - 1s 34us/step - loss: 0.0520 - acc: 0.9846 - val_loss: 0.0339 - val_acc: 0.9881\n",
            "Epoch 7/12\n",
            "29404/29404 [==============================] - 1s 34us/step - loss: 0.0466 - acc: 0.9861 - val_loss: 0.0313 - val_acc: 0.9881\n",
            "Epoch 8/12\n",
            "29404/29404 [==============================] - 1s 34us/step - loss: 0.0480 - acc: 0.9850 - val_loss: 0.0295 - val_acc: 0.9899\n",
            "Epoch 9/12\n",
            "29404/29404 [==============================] - 1s 34us/step - loss: 0.0379 - acc: 0.9879 - val_loss: 0.0297 - val_acc: 0.9897\n",
            "Epoch 10/12\n",
            "29404/29404 [==============================] - 1s 34us/step - loss: 0.0373 - acc: 0.9877 - val_loss: 0.0294 - val_acc: 0.9893\n",
            "Epoch 11/12\n",
            "29404/29404 [==============================] - 1s 34us/step - loss: 0.0327 - acc: 0.9890 - val_loss: 0.0268 - val_acc: 0.9909\n",
            "Epoch 12/12\n",
            "29404/29404 [==============================] - 1s 34us/step - loss: 0.0297 - acc: 0.9902 - val_loss: 0.0264 - val_acc: 0.9907\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f23a0730b10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DITyAt3t7Tto",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SoDozqghCJZ4"
      },
      "source": [
        "## 12. Print the accuracy for classification of digits 5 to 9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9fCxgb5s49Cj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "6b54ed83-6299-48aa-9215-db360518b939"
      },
      "source": [
        "#Testing the model on test and train set\n",
        "score = model.evaluate(x_test_5to9, y_test_5to9)\n",
        "print('Test accuracy:', score[1])\n",
        "score = model.evaluate(x_train_5to9, y_train_5to9)\n",
        "print('Train accuracy:', score[1])\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4861/4861 [==============================] - 0s 52us/step\n",
            "('Test accuracy:', 0.9907426454358277)\n",
            "29404/29404 [==============================] - 1s 50us/step\n",
            "('Train accuracy:', 0.9975853625357094)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LRWizZIpCUKg",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FU-HwvIdH0M-",
        "colab_type": "text"
      },
      "source": [
        "## Sentiment analysis <br> \n",
        "\n",
        "The objective of the second problem is to perform Sentiment analysis from the tweets data collected from the users targeted at various mobile devices.\n",
        "Based on the tweet posted by a user (text), we will classify if the sentiment of the user targeted at a particular mobile device is positive or not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAQDiZHRH0M_",
        "colab_type": "text"
      },
      "source": [
        "### 13. Read the dataset (tweets.csv) and drop the NA's while reading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eXGIe-SH0NA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "b257b7ba-c2d7-4ea5-c1b8-c4c72cfaf3a8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWeWe1eJH0NF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('/gdrive/My Drive/tweets.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbCycn9NbTBe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "736b78b4-6778-4f72-cbb3-41e76babb0de"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9093, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQFGV5K3a2UC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "627a943c-e116-4100-ee2b-eaa8ad38e801"
      },
      "source": [
        "data.sample(5)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>emotion_in_tweet_is_directed_at</th>\n",
              "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2033</th>\n",
              "      <td>#sxsw #evaporation @mention @mention Business ...</td>\n",
              "      <td>iPad or iPhone App</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494</th>\n",
              "      <td>I think I fell a bit more in love with #google...</td>\n",
              "      <td>Google</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2683</th>\n",
              "      <td>Is #Google launching a new social network toda...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No emotion toward brand or product</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2578</th>\n",
              "      <td>#sxsw hardware. iPad #rickshaw bag, #lunatik, ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No emotion toward brand or product</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5097</th>\n",
              "      <td>RT @mention @mention @mention at #sxsw: &amp;quot;...</td>\n",
              "      <td>Apple</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             tweet_text  \\\n",
              "2033  #sxsw #evaporation @mention @mention Business ...   \n",
              "494   I think I fell a bit more in love with #google...   \n",
              "2683  Is #Google launching a new social network toda...   \n",
              "2578  #sxsw hardware. iPad #rickshaw bag, #lunatik, ...   \n",
              "5097  RT @mention @mention @mention at #sxsw: &quot;...   \n",
              "\n",
              "     emotion_in_tweet_is_directed_at  \\\n",
              "2033              iPad or iPhone App   \n",
              "494                           Google   \n",
              "2683                             NaN   \n",
              "2578                             NaN   \n",
              "5097                           Apple   \n",
              "\n",
              "     is_there_an_emotion_directed_at_a_brand_or_product  \n",
              "2033                                   Positive emotion  \n",
              "494                                    Positive emotion  \n",
              "2683                 No emotion toward brand or product  \n",
              "2578                 No emotion toward brand or product  \n",
              "5097                                   Positive emotion  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaQsJEdFagil",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data.dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1hrz5P0at09",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6a451da3-5bcb-49b2-a9f2-e9cf55d93e12"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3291, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuuYAylqbekb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "0a0ee980-f882-4bfd-daf2-7f4fcb6f2a48"
      },
      "source": [
        "data.sample(5)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>emotion_in_tweet_is_directed_at</th>\n",
              "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5546</th>\n",
              "      <td>RT @mention Before It Even Begins, #Apple Wins...</td>\n",
              "      <td>Apple</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>467</th>\n",
              "      <td>Before it even begins, Apple wins #SXSW {link}</td>\n",
              "      <td>Apple</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6956</th>\n",
              "      <td>RT @mention With 150 million mobile users on G...</td>\n",
              "      <td>Other Google product or service</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7950</th>\n",
              "      <td>Hey Marissa Mayer. Please tell us something ne...</td>\n",
              "      <td>Google</td>\n",
              "      <td>Negative emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8162</th>\n",
              "      <td>&amp;quot;At SXSW, Apple schools the marketing exp...</td>\n",
              "      <td>Apple</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             tweet_text  \\\n",
              "5546  RT @mention Before It Even Begins, #Apple Wins...   \n",
              "467      Before it even begins, Apple wins #SXSW {link}   \n",
              "6956  RT @mention With 150 million mobile users on G...   \n",
              "7950  Hey Marissa Mayer. Please tell us something ne...   \n",
              "8162  &quot;At SXSW, Apple schools the marketing exp...   \n",
              "\n",
              "      emotion_in_tweet_is_directed_at  \\\n",
              "5546                            Apple   \n",
              "467                             Apple   \n",
              "6956  Other Google product or service   \n",
              "7950                           Google   \n",
              "8162                            Apple   \n",
              "\n",
              "     is_there_an_emotion_directed_at_a_brand_or_product  \n",
              "5546                                   Positive emotion  \n",
              "467                                    Positive emotion  \n",
              "6956                                   Positive emotion  \n",
              "7950                                   Negative emotion  \n",
              "8162                                   Positive emotion  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPJvTjefH0NI",
        "colab_type": "text"
      },
      "source": [
        "### 14. Preprocess the text and add the preprocessed text in a column with name `text` in the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iec5s9gH0NI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(text):\n",
        "    try:\n",
        "        return text.decode('ascii')\n",
        "    except Exception as e:\n",
        "        return \"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQSmqA-vH0NT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['text'] = [preprocess(text) for text in data.tweet_text]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kX-WoJDH0NV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "ebbf1ca6-a2d7-4e38-f95e-739d9d651da3"
      },
      "source": [
        "data.sample(5)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>emotion_in_tweet_is_directed_at</th>\n",
              "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5620</th>\n",
              "      <td>So @mention claims Android phones were everywh...</td>\n",
              "      <td>iPhone</td>\n",
              "      <td>Positive emotion</td>\n",
              "      <td>So @mention claims Android phones were everywh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4580</th>\n",
              "      <td>@mention New iPad Apps For Speech Therapy And ...</td>\n",
              "      <td>iPad or iPhone App</td>\n",
              "      <td>Positive emotion</td>\n",
              "      <td>@mention New iPad Apps For Speech Therapy And ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4721</th>\n",
              "      <td>Anybody know whether I can nab white, 3G, 64GB...</td>\n",
              "      <td>iPad</td>\n",
              "      <td>Positive emotion</td>\n",
              "      <td>Anybody know whether I can nab white, 3G, 64GB...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1604</th>\n",
              "      <td>Woo hoo! @mention is finally back on the iPhon...</td>\n",
              "      <td>iPhone</td>\n",
              "      <td>Positive emotion</td>\n",
              "      <td>Woo hoo! @mention is finally back on the iPhon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2432</th>\n",
              "      <td>#tech iPad 2 Gets Temporary #Apple_Store for #...</td>\n",
              "      <td>iPad</td>\n",
              "      <td>Positive emotion</td>\n",
              "      <td>#tech iPad 2 Gets Temporary #Apple_Store for #...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             tweet_text  \\\n",
              "5620  So @mention claims Android phones were everywh...   \n",
              "4580  @mention New iPad Apps For Speech Therapy And ...   \n",
              "4721  Anybody know whether I can nab white, 3G, 64GB...   \n",
              "1604  Woo hoo! @mention is finally back on the iPhon...   \n",
              "2432  #tech iPad 2 Gets Temporary #Apple_Store for #...   \n",
              "\n",
              "     emotion_in_tweet_is_directed_at  \\\n",
              "5620                          iPhone   \n",
              "4580              iPad or iPhone App   \n",
              "4721                            iPad   \n",
              "1604                          iPhone   \n",
              "2432                            iPad   \n",
              "\n",
              "     is_there_an_emotion_directed_at_a_brand_or_product  \\\n",
              "5620                                   Positive emotion   \n",
              "4580                                   Positive emotion   \n",
              "4721                                   Positive emotion   \n",
              "1604                                   Positive emotion   \n",
              "2432                                   Positive emotion   \n",
              "\n",
              "                                                   text  \n",
              "5620  So @mention claims Android phones were everywh...  \n",
              "4580  @mention New iPad Apps For Speech Therapy And ...  \n",
              "4721  Anybody know whether I can nab white, 3G, 64GB...  \n",
              "1604  Woo hoo! @mention is finally back on the iPhon...  \n",
              "2432  #tech iPad 2 Gets Temporary #Apple_Store for #...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGWB3P2WH0NY",
        "colab_type": "text"
      },
      "source": [
        "### 15. Consider only rows having Positive emotion and Negative emotion and remove other rows from the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdgA_8N2H0NY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data[ (data[\"is_there_an_emotion_directed_at_a_brand_or_product\"] == \"Positive emotion\") | (data[\"is_there_an_emotion_directed_at_a_brand_or_product\"] == \"Negative emotion\")]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Jlu-reIH0Na",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f50021aa-116a-4cda-f632-a597a866b8f4"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3191, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWN66y4cgDxY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SotCRvkDH0Nf",
        "colab_type": "text"
      },
      "source": [
        "### 16. Represent text as numerical data using `CountVectorizer` and get the document term frequency matrix\n",
        "\n",
        "#### Use `vect` as the variable name for initialising CountVectorizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcbkY4sgH0Ng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vect = CountVectorizer(analyzer = \"word\",   \\\n",
        "                             tokenizer = None,    \\\n",
        "                             preprocessor = None, \\\n",
        "                             stop_words = None   ) \n",
        "\n",
        "\n",
        "train_data_features = vect.fit_transform(data.text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyXtZGr-H0Nl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f68b6a66-8a93-4f46-8ef8-18a7df024798"
      },
      "source": [
        "train_data_features.shape"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3191, 5482)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4LUM-XPH0Nn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Numpy arrays are easy to work with, so convert the result to an \n",
        "# array\n",
        "train_data_features = train_data_features.toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIdZYxJtH0Nq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pxd5fSHH0Nt",
        "colab_type": "text"
      },
      "source": [
        "### 17. Find number of different words in vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1DQ2LdNH0Nu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "terms = vect.get_feature_names()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUzAKU5njHgp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b3e0307c-a659-475d-81fe-25176198eb7b"
      },
      "source": [
        "len(terms)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5482"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwtgjTBeH0Ny",
        "colab_type": "text"
      },
      "source": [
        "#### Tip: To see all available functions for an Object use dir"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2n_iCcTNH0N0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShA6D8jKH0N5",
        "colab_type": "text"
      },
      "source": [
        "### 18. Find out how many Positive and Negative emotions are there.\n",
        "\n",
        "Hint: Use value_counts on that column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7LAl5pzH0N6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "1cc063a2-03b1-4734-cfb8-eefa81508e0f"
      },
      "source": [
        "data[\"is_there_an_emotion_directed_at_a_brand_or_product\"].value_counts()"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Positive emotion    2672\n",
              "Negative emotion     519\n",
              "Name: is_there_an_emotion_directed_at_a_brand_or_product, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OgjNJf6kNP5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUvgj0FoH0N9",
        "colab_type": "text"
      },
      "source": [
        "### 19. Change the labels for Positive and Negative emotions as 1 and 0 respectively and store in a different column in the same dataframe named 'Label'\n",
        "\n",
        "Hint: use map on that column and give labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YftKwFv7H0N9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['Label'] = data[\"is_there_an_emotion_directed_at_a_brand_or_product\"].map({'Positive emotion': '1', 'Negative emotion': '0'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0AcEoawoRvz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "9172805f-1458-457c-c8a6-33edd71850c5"
      },
      "source": [
        "data.sample(5)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>emotion_in_tweet_is_directed_at</th>\n",
              "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
              "      <th>text</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4975</th>\n",
              "      <td>@mention oh hey i remember that :) didn't even...</td>\n",
              "      <td>iPad</td>\n",
              "      <td>Positive emotion</td>\n",
              "      <td>@mention oh hey i remember that :) didn't even...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2105</th>\n",
              "      <td>Android party #sxsw (@mention Lustre Pearl Bar...</td>\n",
              "      <td>Android</td>\n",
              "      <td>Positive emotion</td>\n",
              "      <td>Android party #sxsw (@mention Lustre Pearl Bar...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2322</th>\n",
              "      <td>@mention Can not wait for #iPad 2 also. They s...</td>\n",
              "      <td>iPad</td>\n",
              "      <td>Positive emotion</td>\n",
              "      <td>@mention Can not wait for #iPad 2 also. They s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7370</th>\n",
              "      <td>Verizon IPhone at #SXSW = 5 bars, baby.  Suck ...</td>\n",
              "      <td>iPhone</td>\n",
              "      <td>Positive emotion</td>\n",
              "      <td>Verizon IPhone at #SXSW = 5 bars, baby.  Suck ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2632</th>\n",
              "      <td>One of the best photo apps for the iPhone ��� ...</td>\n",
              "      <td>iPad or iPhone App</td>\n",
              "      <td>Positive emotion</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             tweet_text  \\\n",
              "4975  @mention oh hey i remember that :) didn't even...   \n",
              "2105  Android party #sxsw (@mention Lustre Pearl Bar...   \n",
              "2322  @mention Can not wait for #iPad 2 also. They s...   \n",
              "7370  Verizon IPhone at #SXSW = 5 bars, baby.  Suck ...   \n",
              "2632  One of the best photo apps for the iPhone ��� ...   \n",
              "\n",
              "     emotion_in_tweet_is_directed_at  \\\n",
              "4975                            iPad   \n",
              "2105                         Android   \n",
              "2322                            iPad   \n",
              "7370                          iPhone   \n",
              "2632              iPad or iPhone App   \n",
              "\n",
              "     is_there_an_emotion_directed_at_a_brand_or_product  \\\n",
              "4975                                   Positive emotion   \n",
              "2105                                   Positive emotion   \n",
              "2322                                   Positive emotion   \n",
              "7370                                   Positive emotion   \n",
              "2632                                   Positive emotion   \n",
              "\n",
              "                                                   text Label  \n",
              "4975  @mention oh hey i remember that :) didn't even...     1  \n",
              "2105  Android party #sxsw (@mention Lustre Pearl Bar...     1  \n",
              "2322  @mention Can not wait for #iPad 2 also. They s...     1  \n",
              "7370  Verizon IPhone at #SXSW = 5 bars, baby.  Suck ...     1  \n",
              "2632                                                        1  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YErwYLCH0N_",
        "colab_type": "text"
      },
      "source": [
        "### 20. Define the feature set (independent variable or X) to be `text` column and `labels` as target (or dependent variable)  and divide into train and test datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNkwrGgEH0OA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = train_data_features\n",
        "Y = data['Label']\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state=7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EDBn-0trcqV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5nlCuaaH0OD",
        "colab_type": "text"
      },
      "source": [
        "## 21. **Predicting the sentiment:**\n",
        "\n",
        "\n",
        "### Use Naive Bayes and Logistic Regression and their accuracy scores for predicting the sentiment of the given text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AbVYssaH0OE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktXrLhmOH0Of",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4b5fba31-416f-42d4-b6ad-fef4e0dfa9fe"
      },
      "source": [
        "#Fit the model\n",
        "model = GaussianNB()\n",
        "model.fit(x_train, y_train)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(priors=None, var_smoothing=1e-09)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clv2X0kKH0Ok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_predictTest=model.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K86LRMfdH0Ou",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4b8e03bb-2a37-4c1b-b596-c728f59077e8"
      },
      "source": [
        "metrics.accuracy_score(y_test,y_predictTest)\n"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7433489827856025"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14jVnsSRsCsu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "f40ba692-5fde-4943-9b72-43659d62f4bd"
      },
      "source": [
        "#Fit the model\n",
        "model = LogisticRegression()\n",
        "model.fit(x_train, y_train)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
              "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
              "          tol=0.0001, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRlHZ9-fsC2V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5c4775ba-2901-4a6e-f3b3-c1a1df493341"
      },
      "source": [
        "y_predictTest=model.predict(x_test)\n",
        "metrics.accuracy_score(y_test,y_predictTest)\n"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.863849765258216"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sw-0B33tH0Ox",
        "colab_type": "text"
      },
      "source": [
        "## 22. Create a function called `tokenize_predict` which can take count vectorizer object as input and prints the accuracy for x (text) and y (labels)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okCTOs1TH0Oy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize_predict(vect):\n",
        "   X =  vect.fit_transform(data.text)\n",
        "   x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=7)\n",
        "   print('Features: ', x_train.shape[1])\n",
        "   nb = MultinomialNB()\n",
        "   nb.fit(x_train, y_train)\n",
        "   y_pred_class = nb.predict(x_test)\n",
        "   print('Accuracy: ', metrics.accuracy_score(y_test, y_pred_class))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxZ8jfPEH0O0",
        "colab_type": "text"
      },
      "source": [
        "### Create a count vectorizer function which includes n_grams = 1,2  and pass it to tokenize_predict function to print the accuracy score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdCyAN_IH0O0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
        "# bag of words tool.  \n",
        "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
        "                             ngram_range=(1,2)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axepytmgH0O4",
        "colab_type": "text"
      },
      "source": [
        "### Create a count vectorizer function with stopwords = 'english'  and pass it to tokenize_predict function to print the accuracy score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HToGkq7vH0O4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "29b7c7ff-5f34-49e9-e49d-c322d0d326f5"
      },
      "source": [
        "tokenize_predict(vectorizer)\n"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Features: ', 28958)\n",
            "('Accuracy: ', 0.8652751423149905)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOIlJRxoH0O7",
        "colab_type": "text"
      },
      "source": [
        "### Create a count vectorizer function with stopwords = 'english' and max_features =300  and pass it to tokenize_predict function to print the accuracy score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fUhff-oH0O8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "2ebb2729-e4f1-437d-cadd-795b89ea7cfd"
      },
      "source": [
        "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
        "                             stop_words = \"english\",   \\\n",
        "                             max_features = 300) \n",
        "tokenize_predict(vectorizer)\n"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Features: ', 300)\n",
            "('Accuracy: ', 0.8358633776091081)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2KZNWVkH0PA",
        "colab_type": "text"
      },
      "source": [
        "### Create a count vectorizer function with n_grams = 1,2  and max_features = 15000  and pass it to tokenize_predict function to print the accuracy score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3v9XD082H0PB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "6c4deafc-ff4d-45ad-d7e6-ae16e09b0bf4"
      },
      "source": [
        "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
        "                             ngram_range=(1,2),   \\\n",
        "                             max_features = 15000) \n",
        "tokenize_predict(vectorizer)\n"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Features: ', 15000)\n",
            "('Accuracy: ', 0.8595825426944972)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "We3JK_SRH0PO",
        "colab_type": "text"
      },
      "source": [
        "### Create a count vectorizer function with n_grams = 1,2  and include terms that appear at least 2 times (min_df = 2)  and pass it to tokenize_predict function to print the accuracy score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUHrfDCyH0PP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "a9a03e31-022b-45ec-a856-f2addd07d30c"
      },
      "source": [
        "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
        "                             ngram_range=(1,2),   \\\n",
        "                             min_df = 2) \n",
        "tokenize_predict(vectorizer)\n"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Features: ', 9914)\n",
            "('Accuracy: ', 0.8425047438330171)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H4k_lVZH0PS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}